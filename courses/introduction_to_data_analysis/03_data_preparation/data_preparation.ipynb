{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e49b88f",
   "metadata": {},
   "source": [
    "### Sections\n",
    "\n",
    "1. [Introduction](#introduction)\n",
    "2. [Loading the dataset into a DataFrame](#loading-the-dataset-into-a-dataframe)\n",
    "3. [Choosing questions for our analysis](#choosing-questions-for-our-analysis)\n",
    "4. [Converting data to the correct dtype](#converting-data-to-the-correct-dtype)  \n",
    "    4.1. [Introduction](#4-introduction)  \n",
    "    4.2. [Converting the dtype of the \"duration (seconds)\" column](#converting-the-dtype-of-the-duration-(seconds)-column)  \n",
    "    4.3. [Converting the dtype of the \"latitude\" column](#converting-the-dtype-of-the-latitude-column)  \n",
    "    4.4. [Converting the dtype of the \"datetime\" column](#converting-the-dtype-of-the-datetime-column)  \n",
    "    4.5. [Converting the dtype of the \"date posted\" column](#converting-the-dtype-of-the-date-posted-column)\n",
    "5. [Handling missing data](#handling-missing-data)  \n",
    "    5.1. [Introduction](#5-introduction)  \n",
    "    5.2. [Handling missing data in the shape column](#handling-missing-data-in-the-shape-column)  \n",
    "    5.3. [Handling missing data in the \"state\" and \"country\" columns](#handling-missing-data-in-the-country-and-state-columns)  \n",
    "6. [Removing duplicate data](#removing-duplicate-data)\n",
    "7. [Saving the processed dataset to a file](#saving-the-processed-dataset-to-a-file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2b14ca",
   "metadata": {},
   "source": [
    "# 1. Introduction <a id='introduction'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1602fa49",
   "metadata": {},
   "source": [
    "In this notebook, we will be working with a dataset from [www.kaggle.com](www.kaggle.com) - a website that contains many different datasets and which regularly hosts data science competitions. \n",
    "\n",
    "The dataset we will be working with contains data regarding UFO sightings - you can learn more about it [here](https://data.world/timothyrenner/ufo-sightings). The first step is to load the dataset into a dataframe from a url, which can be done with the `read_csv()` function in the Pandas library. The code cell below stores the url to the dataset file  in the variable `dataset_url`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a178b44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_url = \"https://raw.githubusercontent.com/lazarskiopencourses/lazarskiopencourses.github.io/master/courses/introduction_to_data_analysis/datasets/ufo_sightings.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8649648c",
   "metadata": {},
   "source": [
    "# 2. Loading the dataset into a DataFrame <a id='loading-the-dataset-into-a-dataframe'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c8df09",
   "metadata": {},
   "source": [
    "As you may have noticed, the dataset filename ends in \".csv\". The \"csv\" stands for **c**omma-**s**eparated **v**alues. Csv files are commonly used to store tabular data, where the values for each column are separated by commas, and each row is on its own line.\n",
    "\n",
    "For example, a csv file might look like this:\n",
    "\n",
    "`name, breed, age`  \n",
    "`Coco, Poodle, 4`  \n",
    "`Teddy, Poodle, 2`  \n",
    "`Nala, Husky, 6`  \n",
    "\n",
    "The first row contains the names of the columns, whereas the subsequent rows contain the data. The above example is a small dataset consisting of 3 columns and 3 rows of data (4 rows total, but one row contains column names). The dataset we will be working with in this notebook is much bigger and contains more columns (11 columns), as well as many more rows (80332 rows).\n",
    "\n",
    "The Pandas library has a function for loading a csv file into a `DataFrame` object. So first lets import the pandas library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb29a9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f86f26a8",
   "metadata": {},
   "source": [
    "Now we can pass in the file path as an argument to the `read_csv()` function, which will return a `DataFrame` object containing the data in the csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "31b2d0eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13024/602548147.py:1: DtypeWarning: Columns (5,9) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(dataset_url)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>country</th>\n",
       "      <th>shape</th>\n",
       "      <th>duration (seconds)</th>\n",
       "      <th>duration (hours/min)</th>\n",
       "      <th>comments</th>\n",
       "      <th>date posted</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10/10/1949 20:30</td>\n",
       "      <td>san marcos</td>\n",
       "      <td>tx</td>\n",
       "      <td>us</td>\n",
       "      <td>cylinder</td>\n",
       "      <td>2700</td>\n",
       "      <td>45 minutes</td>\n",
       "      <td>This event took place in early fall around 194...</td>\n",
       "      <td>4/27/2004</td>\n",
       "      <td>29.8830556</td>\n",
       "      <td>-97.941111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10/10/1949 21:00</td>\n",
       "      <td>lackland afb</td>\n",
       "      <td>tx</td>\n",
       "      <td>NaN</td>\n",
       "      <td>light</td>\n",
       "      <td>7200</td>\n",
       "      <td>1-2 hrs</td>\n",
       "      <td>1949 Lackland AFB&amp;#44 TX.  Lights racing acros...</td>\n",
       "      <td>12/16/2005</td>\n",
       "      <td>29.38421</td>\n",
       "      <td>-98.581082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10/10/1955 17:00</td>\n",
       "      <td>chester (uk/england)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gb</td>\n",
       "      <td>circle</td>\n",
       "      <td>20</td>\n",
       "      <td>20 seconds</td>\n",
       "      <td>Green/Orange circular disc over Chester&amp;#44 En...</td>\n",
       "      <td>1/21/2008</td>\n",
       "      <td>53.2</td>\n",
       "      <td>-2.916667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10/10/1956 21:00</td>\n",
       "      <td>edna</td>\n",
       "      <td>tx</td>\n",
       "      <td>us</td>\n",
       "      <td>circle</td>\n",
       "      <td>20</td>\n",
       "      <td>1/2 hour</td>\n",
       "      <td>My older brother and twin sister were leaving ...</td>\n",
       "      <td>1/17/2004</td>\n",
       "      <td>28.9783333</td>\n",
       "      <td>-96.645833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10/10/1960 20:00</td>\n",
       "      <td>kaneohe</td>\n",
       "      <td>hi</td>\n",
       "      <td>us</td>\n",
       "      <td>light</td>\n",
       "      <td>900</td>\n",
       "      <td>15 minutes</td>\n",
       "      <td>AS a Marine 1st Lt. flying an FJ4B fighter/att...</td>\n",
       "      <td>1/22/2004</td>\n",
       "      <td>21.4180556</td>\n",
       "      <td>-157.803611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80327</th>\n",
       "      <td>9/9/2013 21:15</td>\n",
       "      <td>nashville</td>\n",
       "      <td>tn</td>\n",
       "      <td>us</td>\n",
       "      <td>light</td>\n",
       "      <td>600.0</td>\n",
       "      <td>10 minutes</td>\n",
       "      <td>Round from the distance/slowly changing colors...</td>\n",
       "      <td>9/30/2013</td>\n",
       "      <td>36.165833</td>\n",
       "      <td>-86.784444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80328</th>\n",
       "      <td>9/9/2013 22:00</td>\n",
       "      <td>boise</td>\n",
       "      <td>id</td>\n",
       "      <td>us</td>\n",
       "      <td>circle</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>20 minutes</td>\n",
       "      <td>Boise&amp;#44 ID&amp;#44 spherical&amp;#44 20 min&amp;#44 10 r...</td>\n",
       "      <td>9/30/2013</td>\n",
       "      <td>43.613611</td>\n",
       "      <td>-116.202500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80329</th>\n",
       "      <td>9/9/2013 22:00</td>\n",
       "      <td>napa</td>\n",
       "      <td>ca</td>\n",
       "      <td>us</td>\n",
       "      <td>other</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>hour</td>\n",
       "      <td>Napa UFO&amp;#44</td>\n",
       "      <td>9/30/2013</td>\n",
       "      <td>38.297222</td>\n",
       "      <td>-122.284444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80330</th>\n",
       "      <td>9/9/2013 22:20</td>\n",
       "      <td>vienna</td>\n",
       "      <td>va</td>\n",
       "      <td>us</td>\n",
       "      <td>circle</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5 seconds</td>\n",
       "      <td>Saw a five gold lit cicular craft moving fastl...</td>\n",
       "      <td>9/30/2013</td>\n",
       "      <td>38.901111</td>\n",
       "      <td>-77.265556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80331</th>\n",
       "      <td>9/9/2013 23:00</td>\n",
       "      <td>edmond</td>\n",
       "      <td>ok</td>\n",
       "      <td>us</td>\n",
       "      <td>cigar</td>\n",
       "      <td>1020.0</td>\n",
       "      <td>17 minutes</td>\n",
       "      <td>2 witnesses 2  miles apart&amp;#44 Red &amp;amp; White...</td>\n",
       "      <td>9/30/2013</td>\n",
       "      <td>35.652778</td>\n",
       "      <td>-97.477778</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80332 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               datetime                  city state country     shape  \\\n",
       "0      10/10/1949 20:30            san marcos    tx      us  cylinder   \n",
       "1      10/10/1949 21:00          lackland afb    tx     NaN     light   \n",
       "2      10/10/1955 17:00  chester (uk/england)   NaN      gb    circle   \n",
       "3      10/10/1956 21:00                  edna    tx      us    circle   \n",
       "4      10/10/1960 20:00               kaneohe    hi      us     light   \n",
       "...                 ...                   ...   ...     ...       ...   \n",
       "80327    9/9/2013 21:15             nashville    tn      us     light   \n",
       "80328    9/9/2013 22:00                 boise    id      us    circle   \n",
       "80329    9/9/2013 22:00                  napa    ca      us     other   \n",
       "80330    9/9/2013 22:20                vienna    va      us    circle   \n",
       "80331    9/9/2013 23:00                edmond    ok      us     cigar   \n",
       "\n",
       "      duration (seconds) duration (hours/min)  \\\n",
       "0                   2700           45 minutes   \n",
       "1                   7200              1-2 hrs   \n",
       "2                     20           20 seconds   \n",
       "3                     20             1/2 hour   \n",
       "4                    900           15 minutes   \n",
       "...                  ...                  ...   \n",
       "80327              600.0           10 minutes   \n",
       "80328             1200.0           20 minutes   \n",
       "80329             1200.0                 hour   \n",
       "80330                5.0            5 seconds   \n",
       "80331             1020.0           17 minutes   \n",
       "\n",
       "                                                comments date posted  \\\n",
       "0      This event took place in early fall around 194...   4/27/2004   \n",
       "1      1949 Lackland AFB&#44 TX.  Lights racing acros...  12/16/2005   \n",
       "2      Green/Orange circular disc over Chester&#44 En...   1/21/2008   \n",
       "3      My older brother and twin sister were leaving ...   1/17/2004   \n",
       "4      AS a Marine 1st Lt. flying an FJ4B fighter/att...   1/22/2004   \n",
       "...                                                  ...         ...   \n",
       "80327  Round from the distance/slowly changing colors...   9/30/2013   \n",
       "80328  Boise&#44 ID&#44 spherical&#44 20 min&#44 10 r...   9/30/2013   \n",
       "80329                                       Napa UFO&#44   9/30/2013   \n",
       "80330  Saw a five gold lit cicular craft moving fastl...   9/30/2013   \n",
       "80331  2 witnesses 2  miles apart&#44 Red &amp; White...   9/30/2013   \n",
       "\n",
       "         latitude  longitude   \n",
       "0      29.8830556  -97.941111  \n",
       "1        29.38421  -98.581082  \n",
       "2            53.2   -2.916667  \n",
       "3      28.9783333  -96.645833  \n",
       "4      21.4180556 -157.803611  \n",
       "...           ...         ...  \n",
       "80327   36.165833  -86.784444  \n",
       "80328   43.613611 -116.202500  \n",
       "80329   38.297222 -122.284444  \n",
       "80330   38.901111  -77.265556  \n",
       "80331   35.652778  -97.477778  \n",
       "\n",
       "[80332 rows x 11 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(dataset_url)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de5692d",
   "metadata": {},
   "source": [
    "At the bottom of the output in the previous cell we can see that the `DataFrame` has 80332 rows and 11 columns. We can also see that there is some warning displayed (in red) at the top of the output. The warning is about mixed types in columns 5 and 9 - we'll deal with that later, when we will be preparing our data for analysis.\n",
    "\n",
    "The first thing we might want to do is to briefly take a look at the output above and familiarize ourselves with the dataset a bit. Here are some observations about the dataset that we can make, based on the `DataFrame` preview above:\n",
    "1. Each row contains data related to a UFO sighting event.\n",
    "2. Some columns contain quantitative data (duration, longitude, latitude, date)\n",
    "3. Some columns contain qualitative data (city, state, country, shape, comments)\n",
    "4. There are two \"duration\" columns which essentially contain the same data - just in a different format.\n",
    "5. We can see that in the `state` and `country` columns, the following value appears: `NaN`. This is the default representation of missing values in Pandas (more will be said about this later)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6490208d",
   "metadata": {},
   "source": [
    "# 3. Choosing questions for our analysis <a id='choosing-questions-for-our-analysis'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d68ad107",
   "metadata": {},
   "source": [
    "Ok, so we have some sense of the kind of data this dataset contains. Now we can ask ourselves what kind of questions can we answer with this dataset. The questions we choose will in part shape our data preparation process.\n",
    "\n",
    "For this dataset, let's say we want to answer the following questions:\n",
    "\n",
    "1. What is the most commonly reported UFO shape?\n",
    "2. What is the average duration of a UFO sighting?\n",
    "3. When do UFO sightings occur?\n",
    "4. Where do UFO sightings occur?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc1721d5",
   "metadata": {},
   "source": [
    "# 4. Converting data to the correct dtype <a id='converting-data-to-the-correct-dtype'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5494f89",
   "metadata": {},
   "source": [
    "## 4.1. Introduction <a id='4-introduction'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "904ccdb6",
   "metadata": {},
   "source": [
    "When preparing data for analysis, it is good to start by making sure that the data in each column is of the correct `dtype`. For example, if we have a column containing numerical data, we want to store it as a numerical `dtype` (such as `float64` for example), because otherwise we might not be able to perform certain operations on the data in that column (such as arithmetic operations). \n",
    "\n",
    "Before we proceed to checking (and potentially correcting) the `dtype` of each column in our dataframe, it is worth knowing two things:\n",
    "\n",
    "1. By default, columns with strings are assigned the `object` dtype in Pandas. The `object` dtype actually corresponds to any Python object - a list, a dictionary, a string, an integer etc. This means that a column with the `object` dtype can store any Python object. It is also important to know that the `object` dtype is the default `dtype` in Pandas. This means that columns with data of mixed types, or data whose `dtype` cannot be inferred by Pandas, will be assigned the `object` dtype by default. \n",
    "\n",
    "\n",
    "2. Pandas (and NumPy) have a special `dtype` for dates and times, since this kind of data is quite common. The `datetime64` dtype is used for storing both the date and time (as the name suggests)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332aa66d",
   "metadata": {},
   "source": [
    "Ok, so if we want to check the data types of our columns, we can use the `DataFrame.dtypes` attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84b01341",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime                 object\n",
       "city                     object\n",
       "state                    object\n",
       "country                  object\n",
       "shape                    object\n",
       "duration (seconds)       object\n",
       "duration (hours/min)     object\n",
       "comments                 object\n",
       "date posted              object\n",
       "latitude                 object\n",
       "longitude               float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ec652e",
   "metadata": {},
   "source": [
    "We can see that almost all of the columns are of the default `object` dtype. For columns such as \"country\" or \"comments\" this is ok, since those columns only contain strings. However, columns \"duration (seconds)\" and \"latitude\" contain numerical data. Furthermore, the column \"datetime\" contains dates and times, and the column \"date posted\" contains just dates.\n",
    "\n",
    "Therefore the following columns should be converted to the correct dtypes:\n",
    "\n",
    "    \n",
    "|Column name          | Current dtype| Target dtype|\n",
    "|:--------------------|:-------------|:------------|\n",
    "|duration (seconds)   |object        | int64       |\n",
    "|latitude             |object        | float64     |\n",
    "|datetime             |object        | datetime64  |\n",
    "|date posted          |object        | datetime64  |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f30b4a3",
   "metadata": {},
   "source": [
    "## 4.2. Converting the dtype of the \"duration (seconds)\" column <a id='converting-the-dtype-of-the-duration-(seconds)-column'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630c205f",
   "metadata": {},
   "source": [
    "We can convert columns to different data types by using the `Series.astype()` method. Lets start with the \"duration (seconds)\" column.\n",
    "\n",
    "**Note:** running the code cell below will result in an error - this is supposed to happen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f8fc941",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: '1.5'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mduration (seconds)\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mduration (seconds)\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mint64\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/online_courses/lib/python3.9/site-packages/pandas/core/generic.py:5912\u001b[0m, in \u001b[0;36mNDFrame.astype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m   5905\u001b[0m     results \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m   5906\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miloc[:, i]\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[1;32m   5907\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns))\n\u001b[1;32m   5908\u001b[0m     ]\n\u001b[1;32m   5910\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   5911\u001b[0m     \u001b[38;5;66;03m# else, only a single dtype is given\u001b[39;00m\n\u001b[0;32m-> 5912\u001b[0m     new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5913\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor(new_data)\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mastype\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   5915\u001b[0m \u001b[38;5;66;03m# GH 33113: handle empty frame or series\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/online_courses/lib/python3.9/site-packages/pandas/core/internals/managers.py:419\u001b[0m, in \u001b[0;36mBaseBlockManager.astype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m    418\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mastype\u001b[39m(\u001b[38;5;28mself\u001b[39m: T, dtype, copy: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, errors: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[0;32m--> 419\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mastype\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/online_courses/lib/python3.9/site-packages/pandas/core/internals/managers.py:304\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[0;34m(self, f, align_keys, ignore_failures, **kwargs)\u001b[0m\n\u001b[1;32m    302\u001b[0m         applied \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39mapply(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    303\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 304\u001b[0m         applied \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mNotImplementedError\u001b[39;00m):\n\u001b[1;32m    306\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ignore_failures:\n",
      "File \u001b[0;32m~/anaconda3/envs/online_courses/lib/python3.9/site-packages/pandas/core/internals/blocks.py:580\u001b[0m, in \u001b[0;36mBlock.astype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m    562\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    563\u001b[0m \u001b[38;5;124;03mCoerce to the new dtype.\u001b[39;00m\n\u001b[1;32m    564\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    576\u001b[0m \u001b[38;5;124;03mBlock\u001b[39;00m\n\u001b[1;32m    577\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    578\u001b[0m values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues\n\u001b[0;32m--> 580\u001b[0m new_values \u001b[38;5;241m=\u001b[39m \u001b[43mastype_array_safe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    582\u001b[0m new_values \u001b[38;5;241m=\u001b[39m maybe_coerce_values(new_values)\n\u001b[1;32m    583\u001b[0m newb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_block(new_values)\n",
      "File \u001b[0;32m~/anaconda3/envs/online_courses/lib/python3.9/site-packages/pandas/core/dtypes/cast.py:1292\u001b[0m, in \u001b[0;36mastype_array_safe\u001b[0;34m(values, dtype, copy, errors)\u001b[0m\n\u001b[1;32m   1289\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtype\u001b[38;5;241m.\u001b[39mnumpy_dtype\n\u001b[1;32m   1291\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1292\u001b[0m     new_values \u001b[38;5;241m=\u001b[39m \u001b[43mastype_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1293\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[1;32m   1294\u001b[0m     \u001b[38;5;66;03m# e.g. astype_nansafe can fail on object-dtype of strings\u001b[39;00m\n\u001b[1;32m   1295\u001b[0m     \u001b[38;5;66;03m#  trying to convert to float\u001b[39;00m\n\u001b[1;32m   1296\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/online_courses/lib/python3.9/site-packages/pandas/core/dtypes/cast.py:1237\u001b[0m, in \u001b[0;36mastype_array\u001b[0;34m(values, dtype, copy)\u001b[0m\n\u001b[1;32m   1234\u001b[0m     values \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[1;32m   1236\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1237\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[43mastype_nansafe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1239\u001b[0m \u001b[38;5;66;03m# in pandas we don't store numpy str dtypes, so convert to object\u001b[39;00m\n\u001b[1;32m   1240\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, np\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(values\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype, \u001b[38;5;28mstr\u001b[39m):\n",
      "File \u001b[0;32m~/anaconda3/envs/online_courses/lib/python3.9/site-packages/pandas/core/dtypes/cast.py:1154\u001b[0m, in \u001b[0;36mastype_nansafe\u001b[0;34m(arr, dtype, copy, skipna)\u001b[0m\n\u001b[1;32m   1150\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_object_dtype(arr\u001b[38;5;241m.\u001b[39mdtype):\n\u001b[1;32m   1151\u001b[0m \n\u001b[1;32m   1152\u001b[0m     \u001b[38;5;66;03m# work around NumPy brokenness, #1987\u001b[39;00m\n\u001b[1;32m   1153\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39missubdtype(dtype\u001b[38;5;241m.\u001b[39mtype, np\u001b[38;5;241m.\u001b[39minteger):\n\u001b[0;32m-> 1154\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype_intsafe\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1156\u001b[0m     \u001b[38;5;66;03m# if we have a datetime/timedelta array of objects\u001b[39;00m\n\u001b[1;32m   1157\u001b[0m     \u001b[38;5;66;03m# then coerce to a proper dtype and recall astype_nansafe\u001b[39;00m\n\u001b[1;32m   1159\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m is_datetime64_dtype(dtype):\n",
      "File \u001b[0;32m~/anaconda3/envs/online_courses/lib/python3.9/site-packages/pandas/_libs/lib.pyx:668\u001b[0m, in \u001b[0;36mpandas._libs.lib.astype_intsafe\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: '1.5'"
     ]
    }
   ],
   "source": [
    "df[\"duration (seconds)\"] = df[\"duration (seconds)\"].astype(\"int64\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e764f5c",
   "metadata": {},
   "source": [
    "Ok, something went wrong because we see a long error message. If we look at the very bottom of the error message, we can see: `ValueError: invalid literal for int() with base 10: '1.5'`. Pandas is trying to tell us that it cannot convert the string `'1.5'` to an integer. Since we asked Pandas to convert all of the data in the \"seconds (duration)\" column to integers, this means that somewhere in that column there is a string with the value `'1.5'` and it is causing this error. \n",
    "\n",
    "We can also suspect that the problem is connected with the fact that the string contains a decimal number, whereas integers do not have a fractional part. Nevertheless, we have discovered that our initial assumption about the data is incorrect. The \"duration (seconds)\" column contains fractions of seconds and therefore `int64` is not a good `dtype` to convert to, since we will lose some of the precision in our data. In this case, let's try to convert the column `dtype` to `float64` and see if we are successful this time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59405dcf",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '2`'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mduration (seconds)\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mduration (seconds)\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfloat64\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/online_courses/lib/python3.9/site-packages/pandas/core/generic.py:5912\u001b[0m, in \u001b[0;36mNDFrame.astype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m   5905\u001b[0m     results \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m   5906\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miloc[:, i]\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[1;32m   5907\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns))\n\u001b[1;32m   5908\u001b[0m     ]\n\u001b[1;32m   5910\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   5911\u001b[0m     \u001b[38;5;66;03m# else, only a single dtype is given\u001b[39;00m\n\u001b[0;32m-> 5912\u001b[0m     new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5913\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor(new_data)\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mastype\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   5915\u001b[0m \u001b[38;5;66;03m# GH 33113: handle empty frame or series\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/online_courses/lib/python3.9/site-packages/pandas/core/internals/managers.py:419\u001b[0m, in \u001b[0;36mBaseBlockManager.astype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m    418\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mastype\u001b[39m(\u001b[38;5;28mself\u001b[39m: T, dtype, copy: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, errors: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[0;32m--> 419\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mastype\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/online_courses/lib/python3.9/site-packages/pandas/core/internals/managers.py:304\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[0;34m(self, f, align_keys, ignore_failures, **kwargs)\u001b[0m\n\u001b[1;32m    302\u001b[0m         applied \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39mapply(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    303\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 304\u001b[0m         applied \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mNotImplementedError\u001b[39;00m):\n\u001b[1;32m    306\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ignore_failures:\n",
      "File \u001b[0;32m~/anaconda3/envs/online_courses/lib/python3.9/site-packages/pandas/core/internals/blocks.py:580\u001b[0m, in \u001b[0;36mBlock.astype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m    562\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    563\u001b[0m \u001b[38;5;124;03mCoerce to the new dtype.\u001b[39;00m\n\u001b[1;32m    564\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    576\u001b[0m \u001b[38;5;124;03mBlock\u001b[39;00m\n\u001b[1;32m    577\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    578\u001b[0m values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues\n\u001b[0;32m--> 580\u001b[0m new_values \u001b[38;5;241m=\u001b[39m \u001b[43mastype_array_safe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    582\u001b[0m new_values \u001b[38;5;241m=\u001b[39m maybe_coerce_values(new_values)\n\u001b[1;32m    583\u001b[0m newb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_block(new_values)\n",
      "File \u001b[0;32m~/anaconda3/envs/online_courses/lib/python3.9/site-packages/pandas/core/dtypes/cast.py:1292\u001b[0m, in \u001b[0;36mastype_array_safe\u001b[0;34m(values, dtype, copy, errors)\u001b[0m\n\u001b[1;32m   1289\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtype\u001b[38;5;241m.\u001b[39mnumpy_dtype\n\u001b[1;32m   1291\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1292\u001b[0m     new_values \u001b[38;5;241m=\u001b[39m \u001b[43mastype_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1293\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[1;32m   1294\u001b[0m     \u001b[38;5;66;03m# e.g. astype_nansafe can fail on object-dtype of strings\u001b[39;00m\n\u001b[1;32m   1295\u001b[0m     \u001b[38;5;66;03m#  trying to convert to float\u001b[39;00m\n\u001b[1;32m   1296\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/online_courses/lib/python3.9/site-packages/pandas/core/dtypes/cast.py:1237\u001b[0m, in \u001b[0;36mastype_array\u001b[0;34m(values, dtype, copy)\u001b[0m\n\u001b[1;32m   1234\u001b[0m     values \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[1;32m   1236\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1237\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[43mastype_nansafe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1239\u001b[0m \u001b[38;5;66;03m# in pandas we don't store numpy str dtypes, so convert to object\u001b[39;00m\n\u001b[1;32m   1240\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, np\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(values\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype, \u001b[38;5;28mstr\u001b[39m):\n",
      "File \u001b[0;32m~/anaconda3/envs/online_courses/lib/python3.9/site-packages/pandas/core/dtypes/cast.py:1181\u001b[0m, in \u001b[0;36mastype_nansafe\u001b[0;34m(arr, dtype, copy, skipna)\u001b[0m\n\u001b[1;32m   1177\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[1;32m   1179\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;129;01mor\u001b[39;00m is_object_dtype(arr\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mor\u001b[39;00m is_object_dtype(dtype):\n\u001b[1;32m   1180\u001b[0m     \u001b[38;5;66;03m# Explicit copy, or required since NumPy can't view from / to object.\u001b[39;00m\n\u001b[0;32m-> 1181\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   1183\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: '2`'"
     ]
    }
   ],
   "source": [
    "df[\"duration (seconds)\"] = df[\"duration (seconds)\"].astype(\"float64\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16d6ea5",
   "metadata": {},
   "source": [
    "And we got another error message. This time Pandas is telling us that it cannot convert the string ```'2`'``` to a `float`. We can see that there is something something strange with this string - it contains the following character: ``` ` ```. Its unclear what the ``` ` ``` is supposed to mean. It is most likely a mistake and it should not be there. We can also suspect that it is also the cause of this error, as Pandas does not know how to deal with this character when converting the string to a `float`.\n",
    "\n",
    "Let's fix this by replacing the value ```'2`'``` with `'2'`. We can use do this with the `Series.replace()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42485024",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"duration (seconds)\"] = df[\"duration (seconds)\"].replace(\"2`\", \"2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43bdd9cc",
   "metadata": {},
   "source": [
    "Now lets try to convert the dtype of this column to `float64` again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d62c643f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '8`'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mduration (seconds)\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mduration (seconds)\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfloat64\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/online_courses/lib/python3.9/site-packages/pandas/core/generic.py:5912\u001b[0m, in \u001b[0;36mNDFrame.astype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m   5905\u001b[0m     results \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m   5906\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miloc[:, i]\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[1;32m   5907\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns))\n\u001b[1;32m   5908\u001b[0m     ]\n\u001b[1;32m   5910\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   5911\u001b[0m     \u001b[38;5;66;03m# else, only a single dtype is given\u001b[39;00m\n\u001b[0;32m-> 5912\u001b[0m     new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5913\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor(new_data)\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mastype\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   5915\u001b[0m \u001b[38;5;66;03m# GH 33113: handle empty frame or series\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/online_courses/lib/python3.9/site-packages/pandas/core/internals/managers.py:419\u001b[0m, in \u001b[0;36mBaseBlockManager.astype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m    418\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mastype\u001b[39m(\u001b[38;5;28mself\u001b[39m: T, dtype, copy: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, errors: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[0;32m--> 419\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mastype\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/online_courses/lib/python3.9/site-packages/pandas/core/internals/managers.py:304\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[0;34m(self, f, align_keys, ignore_failures, **kwargs)\u001b[0m\n\u001b[1;32m    302\u001b[0m         applied \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39mapply(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    303\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 304\u001b[0m         applied \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mNotImplementedError\u001b[39;00m):\n\u001b[1;32m    306\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ignore_failures:\n",
      "File \u001b[0;32m~/anaconda3/envs/online_courses/lib/python3.9/site-packages/pandas/core/internals/blocks.py:580\u001b[0m, in \u001b[0;36mBlock.astype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m    562\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    563\u001b[0m \u001b[38;5;124;03mCoerce to the new dtype.\u001b[39;00m\n\u001b[1;32m    564\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    576\u001b[0m \u001b[38;5;124;03mBlock\u001b[39;00m\n\u001b[1;32m    577\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    578\u001b[0m values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues\n\u001b[0;32m--> 580\u001b[0m new_values \u001b[38;5;241m=\u001b[39m \u001b[43mastype_array_safe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    582\u001b[0m new_values \u001b[38;5;241m=\u001b[39m maybe_coerce_values(new_values)\n\u001b[1;32m    583\u001b[0m newb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_block(new_values)\n",
      "File \u001b[0;32m~/anaconda3/envs/online_courses/lib/python3.9/site-packages/pandas/core/dtypes/cast.py:1292\u001b[0m, in \u001b[0;36mastype_array_safe\u001b[0;34m(values, dtype, copy, errors)\u001b[0m\n\u001b[1;32m   1289\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtype\u001b[38;5;241m.\u001b[39mnumpy_dtype\n\u001b[1;32m   1291\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1292\u001b[0m     new_values \u001b[38;5;241m=\u001b[39m \u001b[43mastype_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1293\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[1;32m   1294\u001b[0m     \u001b[38;5;66;03m# e.g. astype_nansafe can fail on object-dtype of strings\u001b[39;00m\n\u001b[1;32m   1295\u001b[0m     \u001b[38;5;66;03m#  trying to convert to float\u001b[39;00m\n\u001b[1;32m   1296\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/online_courses/lib/python3.9/site-packages/pandas/core/dtypes/cast.py:1237\u001b[0m, in \u001b[0;36mastype_array\u001b[0;34m(values, dtype, copy)\u001b[0m\n\u001b[1;32m   1234\u001b[0m     values \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[1;32m   1236\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1237\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[43mastype_nansafe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1239\u001b[0m \u001b[38;5;66;03m# in pandas we don't store numpy str dtypes, so convert to object\u001b[39;00m\n\u001b[1;32m   1240\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, np\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(values\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype, \u001b[38;5;28mstr\u001b[39m):\n",
      "File \u001b[0;32m~/anaconda3/envs/online_courses/lib/python3.9/site-packages/pandas/core/dtypes/cast.py:1181\u001b[0m, in \u001b[0;36mastype_nansafe\u001b[0;34m(arr, dtype, copy, skipna)\u001b[0m\n\u001b[1;32m   1177\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[1;32m   1179\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;129;01mor\u001b[39;00m is_object_dtype(arr\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mor\u001b[39;00m is_object_dtype(dtype):\n\u001b[1;32m   1180\u001b[0m     \u001b[38;5;66;03m# Explicit copy, or required since NumPy can't view from / to object.\u001b[39;00m\n\u001b[0;32m-> 1181\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   1183\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: '8`'"
     ]
    }
   ],
   "source": [
    "df[\"duration (seconds)\"] = df[\"duration (seconds)\"].astype(\"float64\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be139dd",
   "metadata": {},
   "source": [
    "Ok, now we we see a similar error message, but this time concerning the string ```'8`'```. It seems that the ``` ` ``` character appears multiple times throughout this column. Let's fix this by removing all occurrences of this character in the \"duration (seconds)\" column. One way to do this is to replace this character with an empty string. We can do this with the `Series.str.replace()` method, which will match substrings as well, not just entire the string.\n",
    "\n",
    "However, before we do this, we should convert the dtype of the \"duration (seconds)\" column to string. This is because the current dtype is `object`, which means that this column can contain any Python object - including a mix of different types of objects. The \"duration (seconds)\" column most likely contains a mix of `int`, `float` and `str`. If we use the `Series.str.replace()` function right now, it may cause unintended consequences, as this function expects all the values in this column to be strings. Therefore, it is best to first convert all the values in the column to strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a525ae49",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"duration (seconds)\"] = df[\"duration (seconds)\"].astype(\"str\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43017c05",
   "metadata": {},
   "source": [
    "Ok, now let's replace all occurrences of ``` ` ``` with an empty string:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "afad548c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"duration (seconds)\"] = df[\"duration (seconds)\"].str.replace(\"`\", \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a31d4b48",
   "metadata": {},
   "source": [
    "Ok, lets try converting the dtype once again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8907a470",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"duration (seconds)\"] = df[\"duration (seconds)\"].astype(\"float64\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac3612b2",
   "metadata": {},
   "source": [
    "Hurray, no error message this time! So why did we do this? Well, since our column now has a numerical `dtype`, we can easily do all sorts of useful operations on it, which would not have been possible if the `dtype` was `object`. Here are some examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "44b0a4f1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min: 0.001\n",
      "max: 97836000.0\n",
      "mean: 9016.889016344669\n",
      "median: 180.0\n"
     ]
    }
   ],
   "source": [
    "print(\"min:\", df[\"duration (seconds)\"].min())\n",
    "print(\"max:\", df[\"duration (seconds)\"].max())\n",
    "print(\"mean:\", df[\"duration (seconds)\"].mean())\n",
    "print(\"median:\", df[\"duration (seconds)\"].median())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "807c1297",
   "metadata": {},
   "source": [
    "**Note:** in the code cell above, we pass in two arguments into the `print()` function. You can pass in an arbitrary number of arguments to the print function, which by default prints all of those arguments separated by white space `' '`. Therefore, the two lines below will print the same thing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dd2b8df6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a b\n",
      "a b\n"
     ]
    }
   ],
   "source": [
    "print(\"a\" + \" \" + \"b\")\n",
    "print(\"a\", \"b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e551737",
   "metadata": {},
   "source": [
    "## 4.3. Converting the dtype of the \"latitude\" column <a id='converting-the-dtype-of-the-latitude-column'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897b6b7a",
   "metadata": {},
   "source": [
    "Let's correct the dtype of the \"latitude\" column next:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a7395ef4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '33q.200088'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [13]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlatitude\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfloat64\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/online_courses/lib/python3.9/site-packages/pandas/core/generic.py:5912\u001b[0m, in \u001b[0;36mNDFrame.astype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m   5905\u001b[0m     results \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m   5906\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miloc[:, i]\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[1;32m   5907\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns))\n\u001b[1;32m   5908\u001b[0m     ]\n\u001b[1;32m   5910\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   5911\u001b[0m     \u001b[38;5;66;03m# else, only a single dtype is given\u001b[39;00m\n\u001b[0;32m-> 5912\u001b[0m     new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5913\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor(new_data)\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mastype\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   5915\u001b[0m \u001b[38;5;66;03m# GH 33113: handle empty frame or series\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/online_courses/lib/python3.9/site-packages/pandas/core/internals/managers.py:419\u001b[0m, in \u001b[0;36mBaseBlockManager.astype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m    418\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mastype\u001b[39m(\u001b[38;5;28mself\u001b[39m: T, dtype, copy: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, errors: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[0;32m--> 419\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mastype\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/online_courses/lib/python3.9/site-packages/pandas/core/internals/managers.py:304\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[0;34m(self, f, align_keys, ignore_failures, **kwargs)\u001b[0m\n\u001b[1;32m    302\u001b[0m         applied \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39mapply(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    303\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 304\u001b[0m         applied \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mNotImplementedError\u001b[39;00m):\n\u001b[1;32m    306\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ignore_failures:\n",
      "File \u001b[0;32m~/anaconda3/envs/online_courses/lib/python3.9/site-packages/pandas/core/internals/blocks.py:580\u001b[0m, in \u001b[0;36mBlock.astype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m    562\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    563\u001b[0m \u001b[38;5;124;03mCoerce to the new dtype.\u001b[39;00m\n\u001b[1;32m    564\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    576\u001b[0m \u001b[38;5;124;03mBlock\u001b[39;00m\n\u001b[1;32m    577\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    578\u001b[0m values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues\n\u001b[0;32m--> 580\u001b[0m new_values \u001b[38;5;241m=\u001b[39m \u001b[43mastype_array_safe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    582\u001b[0m new_values \u001b[38;5;241m=\u001b[39m maybe_coerce_values(new_values)\n\u001b[1;32m    583\u001b[0m newb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_block(new_values)\n",
      "File \u001b[0;32m~/anaconda3/envs/online_courses/lib/python3.9/site-packages/pandas/core/dtypes/cast.py:1292\u001b[0m, in \u001b[0;36mastype_array_safe\u001b[0;34m(values, dtype, copy, errors)\u001b[0m\n\u001b[1;32m   1289\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtype\u001b[38;5;241m.\u001b[39mnumpy_dtype\n\u001b[1;32m   1291\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1292\u001b[0m     new_values \u001b[38;5;241m=\u001b[39m \u001b[43mastype_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1293\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[1;32m   1294\u001b[0m     \u001b[38;5;66;03m# e.g. astype_nansafe can fail on object-dtype of strings\u001b[39;00m\n\u001b[1;32m   1295\u001b[0m     \u001b[38;5;66;03m#  trying to convert to float\u001b[39;00m\n\u001b[1;32m   1296\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/online_courses/lib/python3.9/site-packages/pandas/core/dtypes/cast.py:1237\u001b[0m, in \u001b[0;36mastype_array\u001b[0;34m(values, dtype, copy)\u001b[0m\n\u001b[1;32m   1234\u001b[0m     values \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[1;32m   1236\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1237\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[43mastype_nansafe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1239\u001b[0m \u001b[38;5;66;03m# in pandas we don't store numpy str dtypes, so convert to object\u001b[39;00m\n\u001b[1;32m   1240\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, np\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(values\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype, \u001b[38;5;28mstr\u001b[39m):\n",
      "File \u001b[0;32m~/anaconda3/envs/online_courses/lib/python3.9/site-packages/pandas/core/dtypes/cast.py:1181\u001b[0m, in \u001b[0;36mastype_nansafe\u001b[0;34m(arr, dtype, copy, skipna)\u001b[0m\n\u001b[1;32m   1177\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[1;32m   1179\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;129;01mor\u001b[39;00m is_object_dtype(arr\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mor\u001b[39;00m is_object_dtype(dtype):\n\u001b[1;32m   1180\u001b[0m     \u001b[38;5;66;03m# Explicit copy, or required since NumPy can't view from / to object.\u001b[39;00m\n\u001b[0;32m-> 1181\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   1183\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: '33q.200088'"
     ]
    }
   ],
   "source": [
    "df[\"latitude\"].astype(\"float64\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb102b5",
   "metadata": {},
   "source": [
    "The latitude should just be a number, but there seems to be a letter there, as indicated by the error message. Let's remove all occurrences of this letter (just in case it shows up multiple times):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "49ade56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"latitude\"] = df[\"latitude\"].astype(\"str\")\n",
    "df[\"latitude\"] = df[\"latitude\"].str.replace(\"q\", \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d4c77d7",
   "metadata": {},
   "source": [
    "Now let's try to convert the dtype again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "141312a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"latitude\"] = df[\"latitude\"].astype(\"float64\")\n",
    "df[\"latitude\"].dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e071af",
   "metadata": {},
   "source": [
    "We have successfully converted the `dtype`, let's move on to the next column..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efde1dca",
   "metadata": {},
   "source": [
    "## 4.4. Converting the dtype of the \"datetime\" column <a id='converting-the-dtype-of-the-datetime-column'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d92d57",
   "metadata": {},
   "source": [
    "Now let's correct the dtype of the \"datetime\" column. When converting a column containing strings with dates and times, we should first identify the format in which the date and time is represented. For example, here are three different formats for representing the date and time:\n",
    "\n",
    "1. `05-SEP-17 18:37:21.4931`\n",
    "2. `12:35 24/02/2017`\n",
    "3. `08-23-1978 7:42PM`\n",
    "\n",
    "Pandas also has the ability to infer the format of a datetime string, however, before we use this functionality, we should know what the format is ourselves. This will enable us to verify that Pandas has correctly inferred the format of the date and time.\n",
    "\n",
    "Let's preview the \"datetime\" column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3ef53ab2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        10/10/1949 20:30\n",
       "1        10/10/1949 21:00\n",
       "2        10/10/1955 17:00\n",
       "3        10/10/1956 21:00\n",
       "4        10/10/1960 20:00\n",
       "               ...       \n",
       "80327      9/9/2013 21:15\n",
       "80328      9/9/2013 22:00\n",
       "80329      9/9/2013 22:00\n",
       "80330      9/9/2013 22:20\n",
       "80331      9/9/2013 23:00\n",
       "Name: datetime, Length: 80332, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"datetime\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064cbccc",
   "metadata": {},
   "source": [
    "Based on the data displayed above, we cannot determine which numbers represent the day and which numbers represent the month - we only see the numbers `9` and `10`. So first let's try to determine whether the first number represents the day or the month. There are many ways to do this. Perhaps one simple way is to get a random sample of dates and times from the \"datetime\" column and hope that one of them will contain a number bigger than 12 on the first or second position. \n",
    "\n",
    "Let's try this first. We can use the `Series.sample()` method to get a random sample of values from a `Series`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "766f7d35",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45690      5/5/2004 19:00\n",
       "44250     5/25/2002 22:04\n",
       "55273      7/1/1987 03:00\n",
       "30346     3/10/2012 23:00\n",
       "7721     11/10/2005 21:00\n",
       "9208     11/14/2010 15:32\n",
       "15322     11/6/2007 05:10\n",
       "26752     2/15/2008 24:00\n",
       "54701     7/10/2002 23:56\n",
       "41810      5/1/2014 23:00\n",
       "Name: datetime, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"datetime\"].sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c19981",
   "metadata": {},
   "source": [
    "Since the `Series.sample()` method returns a random sample, the values you see will almost certainly be different each time you run the above code cell. If you do not see any number above 12 on the second position, go ahead and run the code cell above again.\n",
    "\n",
    "If you have successfully obtained a date with a day larger than 12, you can see that the first number represents the month and the second number represents the day. So our datetime string has the following format: `month/day/year hour:minute`\n",
    "\n",
    "It is also important to notice that single digit month numbers do not have a preceding eg. `3/24/2001`, whereas single digit hours do, eg. `07:35`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5432ccf7",
   "metadata": {},
   "source": [
    "Since we now know what the format of the datetime string is, we can convert the dtype of the \"datetime\" column using the `pd.to_datetime()` function. We will also set the `infer_datetime_format` argument to `True`, to see if Pandas can do some work for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9a11f4b2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "hour must be in 0..23: 10/11/2006 24:00",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/online_courses/lib/python3.9/site-packages/dateutil/parser/_parser.py:649\u001b[0m, in \u001b[0;36mparser.parse\u001b[0;34m(self, timestr, default, ignoretz, tzinfos, **kwargs)\u001b[0m\n\u001b[1;32m    648\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 649\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_build_naive\u001b[49m\u001b[43m(\u001b[49m\u001b[43mres\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    650\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/anaconda3/envs/online_courses/lib/python3.9/site-packages/dateutil/parser/_parser.py:1235\u001b[0m, in \u001b[0;36mparser._build_naive\u001b[0;34m(self, res, default)\u001b[0m\n\u001b[1;32m   1233\u001b[0m         repl[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mday\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m monthrange(cyear, cmonth)[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m-> 1235\u001b[0m naive \u001b[38;5;241m=\u001b[39m \u001b[43mdefault\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreplace\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrepl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1237\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m res\u001b[38;5;241m.\u001b[39mweekday \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m res\u001b[38;5;241m.\u001b[39mday:\n",
      "\u001b[0;31mValueError\u001b[0m: hour must be in 0..23",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/online_courses/lib/python3.9/site-packages/pandas/_libs/tslib.pyx:536\u001b[0m, in \u001b[0;36mpandas._libs.tslib.array_to_datetime\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/online_courses/lib/python3.9/site-packages/pandas/_libs/tslibs/parsing.pyx:281\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.parsing.parse_datetime_string\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/online_courses/lib/python3.9/site-packages/dateutil/parser/_parser.py:1368\u001b[0m, in \u001b[0;36mparse\u001b[0;34m(timestr, parserinfo, **kwargs)\u001b[0m\n\u001b[1;32m   1367\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1368\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDEFAULTPARSER\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimestr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/online_courses/lib/python3.9/site-packages/dateutil/parser/_parser.py:651\u001b[0m, in \u001b[0;36mparser.parse\u001b[0;34m(self, timestr, default, ignoretz, tzinfos, **kwargs)\u001b[0m\n\u001b[1;32m    650\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 651\u001b[0m     \u001b[43msix\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_from\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParserError\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m: \u001b[39;49m\u001b[38;5;132;43;01m%s\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimestr\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43me\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    653\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ignoretz:\n",
      "File \u001b[0;32m<string>:3\u001b[0m, in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mParserError\u001b[0m: hour must be in 0..23: 10/11/2006 24:00",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/online_courses/lib/python3.9/site-packages/pandas/_libs/tslib.pyx:547\u001b[0m, in \u001b[0;36mpandas._libs.tslib.array_to_datetime\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: invalid string coercion to datetime",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/online_courses/lib/python3.9/site-packages/dateutil/parser/_parser.py:649\u001b[0m, in \u001b[0;36mparser.parse\u001b[0;34m(self, timestr, default, ignoretz, tzinfos, **kwargs)\u001b[0m\n\u001b[1;32m    648\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 649\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_build_naive\u001b[49m\u001b[43m(\u001b[49m\u001b[43mres\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    650\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/anaconda3/envs/online_courses/lib/python3.9/site-packages/dateutil/parser/_parser.py:1235\u001b[0m, in \u001b[0;36mparser._build_naive\u001b[0;34m(self, res, default)\u001b[0m\n\u001b[1;32m   1233\u001b[0m         repl[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mday\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m monthrange(cyear, cmonth)[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m-> 1235\u001b[0m naive \u001b[38;5;241m=\u001b[39m \u001b[43mdefault\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreplace\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrepl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1237\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m res\u001b[38;5;241m.\u001b[39mweekday \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m res\u001b[38;5;241m.\u001b[39mday:\n",
      "\u001b[0;31mValueError\u001b[0m: hour must be in 0..23",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[0;32mIn [18]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_datetime\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdatetime\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minfer_datetime_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/online_courses/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1051\u001b[0m, in \u001b[0;36mto_datetime\u001b[0;34m(arg, errors, dayfirst, yearfirst, utc, format, exact, unit, infer_datetime_format, origin, cache)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         result \u001b[38;5;241m=\u001b[39m arg\u001b[38;5;241m.\u001b[39mmap(cache_array)\n\u001b[1;32m   1050\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1051\u001b[0m         values \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_listlike\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1052\u001b[0m         result \u001b[38;5;241m=\u001b[39m arg\u001b[38;5;241m.\u001b[39m_constructor(values, index\u001b[38;5;241m=\u001b[39marg\u001b[38;5;241m.\u001b[39mindex, name\u001b[38;5;241m=\u001b[39marg\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m   1053\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arg, (ABCDataFrame, abc\u001b[38;5;241m.\u001b[39mMutableMapping)):\n",
      "File \u001b[0;32m~/anaconda3/envs/online_courses/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:402\u001b[0m, in \u001b[0;36m_convert_listlike_datetimes\u001b[0;34m(arg, format, name, tz, unit, errors, infer_datetime_format, dayfirst, yearfirst, exact)\u001b[0m\n\u001b[1;32m    400\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m infer_datetime_format\n\u001b[1;32m    401\u001b[0m utc \u001b[38;5;241m=\u001b[39m tz \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutc\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 402\u001b[0m result, tz_parsed \u001b[38;5;241m=\u001b[39m \u001b[43mobjects_to_datetime64ns\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    403\u001b[0m \u001b[43m    \u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    404\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdayfirst\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdayfirst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    405\u001b[0m \u001b[43m    \u001b[49m\u001b[43myearfirst\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43myearfirst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    406\u001b[0m \u001b[43m    \u001b[49m\u001b[43mutc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mutc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    407\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    408\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequire_iso8601\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequire_iso8601\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    409\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_object\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    410\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    412\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tz_parsed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    413\u001b[0m     \u001b[38;5;66;03m# We can take a shortcut since the datetime64 numpy array\u001b[39;00m\n\u001b[1;32m    414\u001b[0m     \u001b[38;5;66;03m# is in UTC\u001b[39;00m\n\u001b[1;32m    415\u001b[0m     dta \u001b[38;5;241m=\u001b[39m DatetimeArray(result, dtype\u001b[38;5;241m=\u001b[39mtz_to_dtype(tz_parsed))\n",
      "File \u001b[0;32m~/anaconda3/envs/online_courses/lib/python3.9/site-packages/pandas/core/arrays/datetimes.py:2242\u001b[0m, in \u001b[0;36mobjects_to_datetime64ns\u001b[0;34m(data, dayfirst, yearfirst, utc, errors, require_iso8601, allow_object, allow_mixed)\u001b[0m\n\u001b[1;32m   2240\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m values\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mi8\u001b[39m\u001b[38;5;124m\"\u001b[39m), tz_parsed\n\u001b[1;32m   2241\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[0;32m-> 2242\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[1;32m   2244\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tz_parsed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2245\u001b[0m     \u001b[38;5;66;03m# We can take a shortcut since the datetime64 numpy array\u001b[39;00m\n\u001b[1;32m   2246\u001b[0m     \u001b[38;5;66;03m#  is in UTC\u001b[39;00m\n\u001b[1;32m   2247\u001b[0m     \u001b[38;5;66;03m# Return i8 values to denote unix timestamps\u001b[39;00m\n\u001b[1;32m   2248\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mi8\u001b[39m\u001b[38;5;124m\"\u001b[39m), tz_parsed\n",
      "File \u001b[0;32m~/anaconda3/envs/online_courses/lib/python3.9/site-packages/pandas/core/arrays/datetimes.py:2224\u001b[0m, in \u001b[0;36mobjects_to_datetime64ns\u001b[0;34m(data, dayfirst, yearfirst, utc, errors, require_iso8601, allow_object, allow_mixed)\u001b[0m\n\u001b[1;32m   2222\u001b[0m order: Literal[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m flags\u001b[38;5;241m.\u001b[39mf_contiguous \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2223\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 2224\u001b[0m     result, tz_parsed \u001b[38;5;241m=\u001b[39m \u001b[43mtslib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray_to_datetime\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2225\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mravel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mK\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2226\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2227\u001b[0m \u001b[43m        \u001b[49m\u001b[43mutc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mutc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2228\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdayfirst\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdayfirst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2229\u001b[0m \u001b[43m        \u001b[49m\u001b[43myearfirst\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43myearfirst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2230\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequire_iso8601\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequire_iso8601\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2231\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_mixed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_mixed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2232\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2233\u001b[0m     result \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mreshape(data\u001b[38;5;241m.\u001b[39mshape, order\u001b[38;5;241m=\u001b[39morder)\n\u001b[1;32m   2234\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/anaconda3/envs/online_courses/lib/python3.9/site-packages/pandas/_libs/tslib.pyx:381\u001b[0m, in \u001b[0;36mpandas._libs.tslib.array_to_datetime\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/online_courses/lib/python3.9/site-packages/pandas/_libs/tslib.pyx:613\u001b[0m, in \u001b[0;36mpandas._libs.tslib.array_to_datetime\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/online_courses/lib/python3.9/site-packages/pandas/_libs/tslib.pyx:751\u001b[0m, in \u001b[0;36mpandas._libs.tslib._array_to_datetime_object\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/online_courses/lib/python3.9/site-packages/pandas/_libs/tslib.pyx:742\u001b[0m, in \u001b[0;36mpandas._libs.tslib._array_to_datetime_object\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/online_courses/lib/python3.9/site-packages/pandas/_libs/tslibs/parsing.pyx:281\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.parsing.parse_datetime_string\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/online_courses/lib/python3.9/site-packages/dateutil/parser/_parser.py:1368\u001b[0m, in \u001b[0;36mparse\u001b[0;34m(timestr, parserinfo, **kwargs)\u001b[0m\n\u001b[1;32m   1366\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser(parserinfo)\u001b[38;5;241m.\u001b[39mparse(timestr, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1367\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1368\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDEFAULTPARSER\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimestr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/online_courses/lib/python3.9/site-packages/dateutil/parser/_parser.py:651\u001b[0m, in \u001b[0;36mparser.parse\u001b[0;34m(self, timestr, default, ignoretz, tzinfos, **kwargs)\u001b[0m\n\u001b[1;32m    649\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_naive(res, default)\n\u001b[1;32m    650\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 651\u001b[0m     \u001b[43msix\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_from\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParserError\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m: \u001b[39;49m\u001b[38;5;132;43;01m%s\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimestr\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43me\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    653\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ignoretz:\n\u001b[1;32m    654\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_tzaware(ret, res, tzinfos)\n",
      "File \u001b[0;32m<string>:3\u001b[0m, in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mParserError\u001b[0m: hour must be in 0..23: 10/11/2006 24:00"
     ]
    }
   ],
   "source": [
    "pd.to_datetime(df[\"datetime\"], infer_datetime_format=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d756012",
   "metadata": {},
   "source": [
    "Ok, so we got an error message from Pandas. If we look at the bottom of the error message, it seems to be suggesting that the hours must be between `0` and `23`. We can also see that the error message contains some datetime string (presumably from the \"datetime\" column) which has the number `24` as the hour. \n",
    "\n",
    "Let's replace all those `24` hours with `00`, however, we must be careful not to replace numbers corresponding to the 24th day. One clever way to do this is to replace all the `24:` substrings with `00:`. By adding the colon `:` we ensure that only the hours will be replaced, since the days, months and years use the forward slash `/` as a separator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eaf38c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"datetime\"] = df[\"datetime\"].astype(\"str\")\n",
    "df[\"datetime\"] = df[\"datetime\"].str.replace(\"24:\", \"00:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775fe3b7",
   "metadata": {},
   "source": [
    "Ok, lets try to convert the dtype of the"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b0a69b3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1949-10-10 20:30:00\n",
       "1       1949-10-10 21:00:00\n",
       "2       1955-10-10 17:00:00\n",
       "3       1956-10-10 21:00:00\n",
       "4       1960-10-10 20:00:00\n",
       "                ...        \n",
       "80327   2013-09-09 21:15:00\n",
       "80328   2013-09-09 22:00:00\n",
       "80329   2013-09-09 22:00:00\n",
       "80330   2013-09-09 22:20:00\n",
       "80331   2013-09-09 23:00:00\n",
       "Name: datetime, Length: 80332, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.to_datetime(df[\"datetime\"], infer_datetime_format=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c3904d4",
   "metadata": {},
   "source": [
    "It seems that Pandas was able to infer the datetime format on its own. If it would not have been able to, we would have to manually pass in the datetime format as the `format` argument in the `pd.to_datetime()` function. The `format` argument should be a string containing a specific sequence of characters, which corresponds to our datetime format - you can learn more about this on the [official documentation page](https://pandas.pydata.org/docs/reference/api/pandas.to_datetime.html).\n",
    "\n",
    "**Note:** The code cell above returns a new `Series` object, but we did not assign it to `df[\"datetime\"]`, so let's do that now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6bd23638",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"datetime\"] = pd.to_datetime(df[\"datetime\"], infer_datetime_format=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef5b062",
   "metadata": {},
   "source": [
    "Since we have successfully converted the dtype of our \"datetime\" column, we can now easily do various useful operations. For example, we can extract the second/minute/hour/day/month/year out of each datetime. The code cell below extracts the hour:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f8a5346c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        20\n",
       "1        21\n",
       "2        17\n",
       "3        21\n",
       "4        20\n",
       "         ..\n",
       "80327    21\n",
       "80328    22\n",
       "80329    22\n",
       "80330    22\n",
       "80331    23\n",
       "Name: datetime, Length: 80332, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"datetime\"].dt.hour"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea2a8aa6",
   "metadata": {},
   "source": [
    "We can also use part of the datetime to create masks and filter the dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "72cbbd3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7407    1947-01-10 20:00:00\n",
       "7408    1959-01-10 18:30:00\n",
       "7409    1964-01-10 20:00:00\n",
       "7410    1968-01-10 23:00:00\n",
       "7411    1971-01-10 20:00:00\n",
       "                ...        \n",
       "25495   2014-01-09 18:44:00\n",
       "25496   2014-01-09 19:15:00\n",
       "25497   2014-01-09 19:15:00\n",
       "25498   2014-01-09 21:20:00\n",
       "25499   2014-01-09 21:50:00\n",
       "Name: datetime, Length: 5689, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = df[\"datetime\"].dt.month == 1\n",
    "df[mask][\"datetime\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "42d2eecc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49      1991-10-10 22:00:00\n",
       "50      1991-10-10 22:00:00\n",
       "51      1992-10-10 17:00:00\n",
       "52      1992-10-10 18:00:00\n",
       "53      1992-10-10 20:15:00\n",
       "                ...        \n",
       "80327   2013-09-09 21:15:00\n",
       "80328   2013-09-09 22:00:00\n",
       "80329   2013-09-09 22:00:00\n",
       "80330   2013-09-09 22:20:00\n",
       "80331   2013-09-09 23:00:00\n",
       "Name: datetime, Length: 73781, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = df[\"datetime\"].dt.year > 1990\n",
    "df[mask][\"datetime\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c79b78c",
   "metadata": {},
   "source": [
    "There are also many other useful things we can do, which you can read about on the [official documentation page](https://pandas.pydata.org/docs/user_guide/timeseries.html). As always, it is not important to memorize all of the operations that can be performed on datetime objects in Pandas. It is only important to know that there are a lot of different operations and that if we are trying to do something with datetime objects, it might be worth reading the official documentation or other sources, to try and see if there is a function, which allows us to accomplish our task easily."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "924437dc",
   "metadata": {},
   "source": [
    "## 4.5. Converting the dtype of the \"date posted\" column <a id='converting-the-dtype-of-the-date-posted-column'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630bea62",
   "metadata": {},
   "source": [
    "Ok, let's try to convert the dtype of the \"date posted\" column to `datetime` and let Pandas handle the datetime format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "17ccd197",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"date posted\"] = pd.to_datetime(df[\"date posted\"], infer_datetime_format=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36078193",
   "metadata": {},
   "source": [
    "No error message? Well sometimes the stars align. Let's preview the column to make sure everything is ok - just in case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7bbde8ff",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       2004-04-27\n",
       "1       2005-12-16\n",
       "2       2008-01-21\n",
       "3       2004-01-17\n",
       "4       2004-01-22\n",
       "           ...    \n",
       "80327   2013-09-30\n",
       "80328   2013-09-30\n",
       "80329   2013-09-30\n",
       "80330   2013-09-30\n",
       "80331   2013-09-30\n",
       "Name: date posted, Length: 80332, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"date posted\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8892380c",
   "metadata": {},
   "source": [
    "Everything looks good! Let's move on to handling missing data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad5d3ed",
   "metadata": {},
   "source": [
    "# 5. Handling missing data <a id='handling-missing-data'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eec08c6",
   "metadata": {},
   "source": [
    "## 5.1 Introduction <a id='5-introduction'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c02e8f3",
   "metadata": {},
   "source": [
    "When preparing data for analysis, it is good to start by looking for missing values. In general, there are two things to look for specifically:\n",
    "\n",
    "**1. Missing values that affect our analysis somehow** - these need to be dealt with either by excluding rows with missing values from our analysis, or by doing imputation (replacing missing values with estimates).\n",
    "\n",
    "**2. Missing values that have not been registered properly in Pandas** - the Pandas library has specific types of objects dedicated to representing missing values. Sometimes a column might contain strings such as \"unknown\", \"N/A\", \"?\", which often mean that the data is missing. However, Pandas considers these values to be regular strings instead of a missing data. In this case, it is useful to convert these types of strings to missing values, so that we can easily exclude them from our analyses whenever we need to."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6230d5",
   "metadata": {},
   "source": [
    "One way to check which columns have missing values is to use the `DataFrame.isna()` method combined with the `DataFrame.sum()` method. \n",
    "\n",
    "First let's cover the `DataFrame.isna()` method, which checks for values that are not available (NA). This method returns a new `DataFrame` with each value replaced either by `True` (if it is missing) or `False` (if it is available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "473a3928",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>country</th>\n",
       "      <th>shape</th>\n",
       "      <th>duration (seconds)</th>\n",
       "      <th>duration (hours/min)</th>\n",
       "      <th>comments</th>\n",
       "      <th>date posted</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80327</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80328</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80329</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80330</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80331</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80332 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       datetime   city  state  country  shape  duration (seconds)  \\\n",
       "0         False  False  False    False  False               False   \n",
       "1         False  False  False     True  False               False   \n",
       "2         False  False   True    False  False               False   \n",
       "3         False  False  False    False  False               False   \n",
       "4         False  False  False    False  False               False   \n",
       "...         ...    ...    ...      ...    ...                 ...   \n",
       "80327     False  False  False    False  False               False   \n",
       "80328     False  False  False    False  False               False   \n",
       "80329     False  False  False    False  False               False   \n",
       "80330     False  False  False    False  False               False   \n",
       "80331     False  False  False    False  False               False   \n",
       "\n",
       "       duration (hours/min)  comments  date posted  latitude  longitude   \n",
       "0                     False     False        False     False       False  \n",
       "1                     False     False        False     False       False  \n",
       "2                     False     False        False     False       False  \n",
       "3                     False     False        False     False       False  \n",
       "4                     False     False        False     False       False  \n",
       "...                     ...       ...          ...       ...         ...  \n",
       "80327                 False     False        False     False       False  \n",
       "80328                 False     False        False     False       False  \n",
       "80329                 False     False        False     False       False  \n",
       "80330                 False     False        False     False       False  \n",
       "80331                 False     False        False     False       False  \n",
       "\n",
       "[80332 rows x 11 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d32bca12",
   "metadata": {},
   "source": [
    "Just as a side note, sometimes you may see people use the `DataFrame.isnull()` method. The `.isna()` and `.isnull()` methods are identical and you can use either one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "aa61bea3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>country</th>\n",
       "      <th>shape</th>\n",
       "      <th>duration (seconds)</th>\n",
       "      <th>duration (hours/min)</th>\n",
       "      <th>comments</th>\n",
       "      <th>date posted</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80327</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80328</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80329</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80330</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80331</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80332 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       datetime   city  state  country  shape  duration (seconds)  \\\n",
       "0         False  False  False    False  False               False   \n",
       "1         False  False  False     True  False               False   \n",
       "2         False  False   True    False  False               False   \n",
       "3         False  False  False    False  False               False   \n",
       "4         False  False  False    False  False               False   \n",
       "...         ...    ...    ...      ...    ...                 ...   \n",
       "80327     False  False  False    False  False               False   \n",
       "80328     False  False  False    False  False               False   \n",
       "80329     False  False  False    False  False               False   \n",
       "80330     False  False  False    False  False               False   \n",
       "80331     False  False  False    False  False               False   \n",
       "\n",
       "       duration (hours/min)  comments  date posted  latitude  longitude   \n",
       "0                     False     False        False     False       False  \n",
       "1                     False     False        False     False       False  \n",
       "2                     False     False        False     False       False  \n",
       "3                     False     False        False     False       False  \n",
       "4                     False     False        False     False       False  \n",
       "...                     ...       ...          ...       ...         ...  \n",
       "80327                 False     False        False     False       False  \n",
       "80328                 False     False        False     False       False  \n",
       "80329                 False     False        False     False       False  \n",
       "80330                 False     False        False     False       False  \n",
       "80331                 False     False        False     False       False  \n",
       "\n",
       "[80332 rows x 11 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb7e3de8",
   "metadata": {},
   "source": [
    "Once we have a `DataFrame` containing `True` and `False` values, we can use the `DataFrame.sum()` method to count the number of `True` values. This is because `True` and `False` are usually associated with the numbers 1 and 0, where `True == 1` and `False == 0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "af25460e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "True == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "818002e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "False == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d05e38ff",
   "metadata": {},
   "source": [
    "If we call the `Series.sum()` method, it will return the sum of all values in a `Series`. If we call the `DataFrame.sum()` method, it will return the sum of each `Series`/column separately (stored in a `Series`, where the indices are column names and the values are the sums). The values `True` and `False` are treated as 1's and 0's, and therefore the sum in this case is simply the number of `True` values in a given series.\n",
    "\n",
    "Therefore, if we call `DataFrame.isna()` we get a dataframe with booleans, where each `True` value corresponds to a missing value. If we call the `.sum()` method on such a dataframe, we will receive a Series containing the number of missing values for each column in our original dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9e189640",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime                   0\n",
       "city                       0\n",
       "state                   5797\n",
       "country                 9670\n",
       "shape                   1932\n",
       "duration (seconds)         0\n",
       "duration (hours/min)       0\n",
       "comments                  15\n",
       "date posted                0\n",
       "latitude                   0\n",
       "longitude                  0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eea5f64",
   "metadata": {},
   "source": [
    "As we can see, there are 4 columns with missing values. However, we might want to display the number of missing values as a percentage of the total number of possible values. In this case, we can first check the number of rows in the dataframe using the `len()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "22e09615",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80332"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "154b65f0",
   "metadata": {},
   "source": [
    "Next we can divide the series with missing values by the number of rows in the dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b0b93f8e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime                0.000000\n",
       "city                    0.000000\n",
       "state                   0.072163\n",
       "country                 0.120375\n",
       "shape                   0.024050\n",
       "duration (seconds)      0.000000\n",
       "duration (hours/min)    0.000000\n",
       "comments                0.000187\n",
       "date posted             0.000000\n",
       "latitude                0.000000\n",
       "longitude               0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum() / len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c7664f4",
   "metadata": {},
   "source": [
    "That works, but there's a lot of number and things are a bit difficult to read. Let's rewrite the previous code and also apply a mask to only see the columns with missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bcb52bd3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "state       0.072163\n",
       "country     0.120375\n",
       "shape       0.024050\n",
       "comments    0.000187\n",
       "dtype: float64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_missing = df.isna().sum()\n",
    "s_missing = s_missing / len(df)\n",
    "s_missing[s_missing > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c6980a8",
   "metadata": {},
   "source": [
    "Ok, that's better. We can now see more clearly which columns have missing values.\n",
    "\n",
    "If we wanted to, we could also use the `Series.round()` method to round the values to 2 decimal places and improve readability even further. However, in this case, we have to remember that the percentage of missing values in the \"comments\" column will be displayed as 0 due to rounding. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "49ba0730",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "state       0.07\n",
       "country     0.12\n",
       "shape       0.02\n",
       "comments    0.00\n",
       "dtype: float64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_missing[s_missing > 0].round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e3677c2",
   "metadata": {},
   "source": [
    "It is also worth knowing that there is a `.notna()` method which does the opposite of the `.isna()` method. That is, it replaces each value with `True` if the value is not missing - otherwise it replaces is with `False`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8b77b810",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>country</th>\n",
       "      <th>shape</th>\n",
       "      <th>duration (seconds)</th>\n",
       "      <th>duration (hours/min)</th>\n",
       "      <th>comments</th>\n",
       "      <th>date posted</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80327</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80328</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80329</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80330</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80331</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80332 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       datetime  city  state  country  shape  duration (seconds)  \\\n",
       "0          True  True   True     True   True                True   \n",
       "1          True  True   True    False   True                True   \n",
       "2          True  True  False     True   True                True   \n",
       "3          True  True   True     True   True                True   \n",
       "4          True  True   True     True   True                True   \n",
       "...         ...   ...    ...      ...    ...                 ...   \n",
       "80327      True  True   True     True   True                True   \n",
       "80328      True  True   True     True   True                True   \n",
       "80329      True  True   True     True   True                True   \n",
       "80330      True  True   True     True   True                True   \n",
       "80331      True  True   True     True   True                True   \n",
       "\n",
       "       duration (hours/min)  comments  date posted  latitude  longitude   \n",
       "0                      True      True         True      True        True  \n",
       "1                      True      True         True      True        True  \n",
       "2                      True      True         True      True        True  \n",
       "3                      True      True         True      True        True  \n",
       "4                      True      True         True      True        True  \n",
       "...                     ...       ...          ...       ...         ...  \n",
       "80327                  True      True         True      True        True  \n",
       "80328                  True      True         True      True        True  \n",
       "80329                  True      True         True      True        True  \n",
       "80330                  True      True         True      True        True  \n",
       "80331                  True      True         True      True        True  \n",
       "\n",
       "[80332 rows x 11 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.notna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3306eec4",
   "metadata": {},
   "source": [
    "Therefore, we could also obtain the series with missing value percentages by first using the `.notna()` method in conjunction with `sum()` and `len(df)` to obtain the percentage of non-missing values. Next we can subtract this percentage from 1 to obtain the percentage of missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "45fdaceb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "state       0.07\n",
       "country     0.12\n",
       "shape       0.02\n",
       "comments    0.00\n",
       "dtype: float64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_missing_2 = df.notna().sum() / len(df)\n",
    "s_missing_2 = 1 - s_missing_2\n",
    "s_missing_2 = s_missing_2[s_missing_2 > 0].round(2)\n",
    "s_missing_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487f6b26",
   "metadata": {},
   "source": [
    "## 5.2 Handling missing data in the \"shape\" column <a id='handling-missing-data-in-the-shape-column'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b28ccc",
   "metadata": {},
   "source": [
    "Ok, so the first question we want to answer in our analysis is \"what is the most commonly reported UFO shape?\". From this question we can deduce that we will be using the \"shape\" column. Most likely we will be calculating the mode of the data in the \"shape\" column (the mode is the most frequently occurring value).\n",
    "\n",
    "Based on `s_missing`, we know that roughly 2% of the data is missing in the \"shape\" column. Since we're just going to be calculating the mode, and the vast majority of the data is there, this will not have a significant impact on our findings. Additionally, when presenting the findings of our analysis, we can convey the information about missing data and discuss it's relevancy.\n",
    "\n",
    "However, we should check whether there are any missing values that were not properly registered. To do this, we can use the `Series.unique()` method, which returns an array of all the unique values in a series. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "93b38991",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['cylinder', 'light', 'circle', 'sphere', 'disk', 'fireball',\n",
       "       'unknown', 'oval', 'other', 'cigar', 'rectangle', 'chevron',\n",
       "       'triangle', 'formation', nan, 'delta', 'changing', 'egg',\n",
       "       'diamond', 'flash', 'teardrop', 'cone', 'cross', 'pyramid',\n",
       "       'round', 'crescent', 'flare', 'hexagon', 'dome', 'changed'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"shape\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8adb453",
   "metadata": {},
   "source": [
    "Firstly, it is worth pointing out that one of the values in the \"shape\" column is: `nan`. Notice that there are no quotation marks around the `nan` - this is because it is not a string. The `nan` value is the default representation for missing data in Pandas. As we have already figured out previously, roughly 2% of the values in the \"shape\" column are `nan`. \n",
    "\n",
    "The `nan` object used to represent missing data is actually an object from the numpy library (`numpy.nan`). There are also other objects, which can used to represent missing data, such as the built-in Python object `None`. Multiple objects representing missing data is not ideal as it can get a little confusing. However, the most important thing to remember is that `nan` (`numpy.nan`), `None` and `<NA>` (`pandas.NA`) are meant to represent the same thing - missing data - even though they are different objects in Python.\n",
    "\n",
    "The second thing worth pointing out is that there is an `'unknown'` value. Here it is not clear whether the  string `'unknown'` refers to the fact that a person could not identify the shape of the UFO, or whether the person did not provide any data about the shape (for whatever reason). In the latter case, this value should be counted as a missing value because the data is unavailable.\n",
    "\n",
    "We could try to dig deeper into the origins of this dataset and see whether there is any information on the internet that could help us figure out which is it. If we do not manage to find an answer, we may wish to include this information during the presentation of our analysis.\n",
    "\n",
    "For the purpose of this course, we will assume that the string `'unknown'` should indeed be counted as a missing value. This will allow for a demonstration of how one can add missing values to a dataframe. To do so, we can use the `Series.replace()` method, which enables us to replace one value with another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7b26c245",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing values before: 1932\n",
      "Number of missing values after: 7516\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of missing values before: \" + str(df[\"shape\"].isna().sum()))\n",
    "\n",
    "df[\"shape\"] = df[\"shape\"].replace(\"unknown\", None)\n",
    "\n",
    "print(\"Number of missing values after: \" + str(df[\"shape\"].isna().sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1950b047",
   "metadata": {},
   "source": [
    "## 5.3 Handling missing data in the \"country\" and \"state\" columns <a id='handling-missing-data-in-the-country-and-state-columns'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd221aa",
   "metadata": {},
   "source": [
    "Since in our analysis we will be answering the question \"where are UFO sightings most common?\", we should examine the missing data in the \"country\" and \"state\" columns. Let's first take a look at those columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "89d71d76",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tx</td>\n",
       "      <td>us</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tx</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>gb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tx</td>\n",
       "      <td>us</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hi</td>\n",
       "      <td>us</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80327</th>\n",
       "      <td>tn</td>\n",
       "      <td>us</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80328</th>\n",
       "      <td>id</td>\n",
       "      <td>us</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80329</th>\n",
       "      <td>ca</td>\n",
       "      <td>us</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80330</th>\n",
       "      <td>va</td>\n",
       "      <td>us</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80331</th>\n",
       "      <td>ok</td>\n",
       "      <td>us</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80332 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      state country\n",
       "0        tx      us\n",
       "1        tx     NaN\n",
       "2       NaN      gb\n",
       "3        tx      us\n",
       "4        hi      us\n",
       "...     ...     ...\n",
       "80327    tn      us\n",
       "80328    id      us\n",
       "80329    ca      us\n",
       "80330    va      us\n",
       "80331    ok      us\n",
       "\n",
       "[80332 rows x 2 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = [\"state\", \"country\"]\n",
    "df[cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f0de3b",
   "metadata": {},
   "source": [
    "Ok, the first thing we might observe is that there is a row with a missing value in the \"country\" column, however, the corresponding \"state\" value is not missing. This means we can fill in the missing country value based on the state value.  \n",
    "\n",
    "The second thing we might observe is that there is a row with a missing value in the \"state\" column, however, the corresponding \"country\" value is not missing. In this case, we might want to consider that the \"state\" column may contain \"valid\" missing values. More specifically, some values can be missing because the \"state\" column is not applicable to all countries. For example, Great Britain (presumably labeled with the identifier \"gb\") is not divided into states the same way as the US, so maybe this is why the value is missing. Perhaps in this dataset only US countries have some value in the \"state\" column. Let's see if this is true:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8e1e049b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['us', nan, 'ca', 'au', 'gb'], dtype=object)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = df[\"state\"].notna()\n",
    "df[mask][\"country\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7861d01",
   "metadata": {},
   "source": [
    "It appears our initial guess was wrong - in this dataset there are four countries that have values in the \"state\" column (the `nan` represents a missing value, meaning some rows have a missing value in the \"country\" column, but a non-missing value in the \"state\" column). Let's also check what countries there are in general, just to get a better sense of the dataset as a whole: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6437c943",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['us', nan, 'gb', 'ca', 'au', 'de'], dtype=object)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"country\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb88ce6",
   "metadata": {},
   "source": [
    "It appears that there are 5 different countries and only Germany (presumably labeled with \"de\") does not have any values in the \"state\" column associated with it. Ok, let's check how many \"state\" values are missing, when we exclude Germany from the count, since we will assume that the missing \"state\" values there are valid. First let's create a mask that filters out Germany from the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "23191321",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_no_germany = df[\"country\"] != \"de\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b58939c",
   "metadata": {},
   "source": [
    "Now lets create a mask to only includes rows with missing values in the \"state\" column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c255cca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_missing_state = df[\"state\"].isna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833365d1",
   "metadata": {},
   "source": [
    "If we want to combine those masks, we might try to first apply one mask and then apply the other mask. However, this is not a recommended way of doing things, since once we apply the first mask, the number of rows in the dataframe will be smaller than the number of values in the second mask. You may remember that a mask is actually a boolean array, where each value corresponds to a row. A value of `True` means that the row is filtered out, whereas `False` means that the row is kept. Therefore a mismatch between the number of rows in the dataframe and the number of values in the mask can cause problems. Let's verify that this mismatch exists using the `len()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e41a047e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num rows in df with no mask: 80332\n",
      "num values in 1st mask: 80332\n",
      "num rows in df with 1st mask: 80227\n",
      "num values in 2nd mask: 80332\n"
     ]
    }
   ],
   "source": [
    "print(\"num rows in df with no mask:\", len(df))\n",
    "print(\"num values in 1st mask:\", len(mask_no_germany))\n",
    "print(\"num rows in df with 1st mask:\", len(df[mask_no_germany]))\n",
    "print(\"num values in 2nd mask:\", len(mask_missing_state))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d53216",
   "metadata": {},
   "source": [
    "As we can see, the number of rows is indeed different after the first mask has been applied. As a side note, we have also discovered that a very small number of rows contain \"de\" in the \"country\" column.\n",
    "\n",
    "If we want to apply two masks together, it is best to either:\n",
    "\n",
    "1. first create and apply the first mask. Then create the second mask based on the new filtered dataframe, and then apply the second mask.\n",
    "\n",
    "2. combine both masks together into one mask using the `&` operator.\n",
    "\n",
    "Let's choose the second option. The `&` operator works analogously to the `and` operator, in that it performs an \"and\" operation on each pair of corresponding values in the two masks, and returns a new mask, which contains `True` only in locations where both the first and second masks are also `True`. Let's apply the combined mask and preview the relevant columns in the dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8d7c56f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>gb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>gb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>NaN</td>\n",
       "      <td>gb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>NaN</td>\n",
       "      <td>gb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80214</th>\n",
       "      <td>NaN</td>\n",
       "      <td>gb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80217</th>\n",
       "      <td>NaN</td>\n",
       "      <td>au</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80234</th>\n",
       "      <td>NaN</td>\n",
       "      <td>gb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80254</th>\n",
       "      <td>NaN</td>\n",
       "      <td>gb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80322</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5692 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      state country\n",
       "2       NaN      gb\n",
       "6       NaN      gb\n",
       "18      NaN     NaN\n",
       "20      NaN      gb\n",
       "24      NaN      gb\n",
       "...     ...     ...\n",
       "80214   NaN      gb\n",
       "80217   NaN      au\n",
       "80234   NaN      gb\n",
       "80254   NaN      gb\n",
       "80322   NaN     NaN\n",
       "\n",
       "[5692 rows x 2 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[mask_no_germany & mask_missing_state][cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e6e5934",
   "metadata": {},
   "source": [
    "As we can see at the bottom of the output above, there are 5692 rows with missing values in the \"state\" column and values other than \"de\" in the \"country\" column. These are missing values that should presumably not be missing. Let's see what percentage they constitute of the entire dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bf182468",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07085594781656127"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[mask_no_germany & mask_missing_state]) / len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8682d8cb",
   "metadata": {},
   "source": [
    "It appears that 7.09% of the \"state\" values are missing. At this point we can ask ourselves a few different questions like: what is the meaning of the state column for countries other than the US and are some of the missing state values for those countries valid (due to inapplicability)? Another question we can ask ourselves is whether or not these missing values are even relevant to our analysis? Perhaps we will not be analyzing the location of UFO sightings based on states, but only based on the countries and cities. In this case, the missing values in the \"state\" column do not affect our analysis, since we will not be using the data in that column at all. If that would be the case, we would not have do anything with those missing values and we could just proceed to the next step in our data preparation process.\n",
    "\n",
    "For the purpose of this course, let's say we want to show the frequency of UFO sightings in different states but only for the US. Let's check whether there are any missing state values for the US:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "eeb939d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = (df[\"country\"] == \"us\") & df[\"state\"].isna()\n",
    "len(df[mask])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7db4cea",
   "metadata": {},
   "source": [
    "It appears that there are no missing state values for the US. In that case, we can move on to handling the missing values in the \"country\" column, which definitely should be filled in if possible. Luckily, we can infer the country values based on the values in either the \"city\" column or the \"state\" column. Let's update the `cols` variable and preview the dataset once again, just to get a better sense of what we're working with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ce8f1827",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>san marcos</td>\n",
       "      <td>tx</td>\n",
       "      <td>us</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lackland afb</td>\n",
       "      <td>tx</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chester (uk/england)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>edna</td>\n",
       "      <td>tx</td>\n",
       "      <td>us</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kaneohe</td>\n",
       "      <td>hi</td>\n",
       "      <td>us</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80327</th>\n",
       "      <td>nashville</td>\n",
       "      <td>tn</td>\n",
       "      <td>us</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80328</th>\n",
       "      <td>boise</td>\n",
       "      <td>id</td>\n",
       "      <td>us</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80329</th>\n",
       "      <td>napa</td>\n",
       "      <td>ca</td>\n",
       "      <td>us</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80330</th>\n",
       "      <td>vienna</td>\n",
       "      <td>va</td>\n",
       "      <td>us</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80331</th>\n",
       "      <td>edmond</td>\n",
       "      <td>ok</td>\n",
       "      <td>us</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80332 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       city state country\n",
       "0                san marcos    tx      us\n",
       "1              lackland afb    tx     NaN\n",
       "2      chester (uk/england)   NaN      gb\n",
       "3                      edna    tx      us\n",
       "4                   kaneohe    hi      us\n",
       "...                     ...   ...     ...\n",
       "80327             nashville    tn      us\n",
       "80328                 boise    id      us\n",
       "80329                  napa    ca      us\n",
       "80330                vienna    va      us\n",
       "80331                edmond    ok      us\n",
       "\n",
       "[80332 rows x 3 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = [\"city\", \"state\", \"country\"]\n",
    "df[cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce00b2e3",
   "metadata": {},
   "source": [
    "So we want to fill in missing country values based on the \"city\" or \"state\" column. Let's think about this: there are rows that have a missing value in the \"country\" column, but have some value in the \"city\" or \"state\" column. There might be some other rows with the same value in the \"city\" or \"state\" columns, that also have some non-missing value in the \"country\" column. Therefore, for each city and state, we could check if there is at least one row, which has a non-missing country value, and then use this value to overwrite all the missing country values. \n",
    "\n",
    "This seems like a good way to fill in some missing values, without referring to external data. However, there is something we should consider: what if two countries have a city with the same name or a state with the same identifier. We'll have to account for both of those things in our code, in order to ensure maximum accuracy of our data. Let's create a function that fills in the missing country values either based on the \"city\" column or the \"state\" column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "87c8632e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_in_missing_countries(df, col_to_use):\n",
    "    \n",
    "    # check whether the argument `col_to_use` is either \"city\" or \"state\"\n",
    "    if col_to_use not in (\"city\", \"state\"):\n",
    "        raise ValueError('argument `col_to_use` must be either \"city\" or \"state\"')\n",
    "    \n",
    "    # for loop over each city/state\n",
    "    # NOTE: we want to exclude missing values, therefore we use the `Series.dropna()`\n",
    "    # method, which removes missing values from the Series\n",
    "    for location in df[col_to_use].dropna().unique():\n",
    "\n",
    "        # create a mask based on the location\n",
    "        mask = df[col_to_use] == location\n",
    "        \n",
    "        # get all of the unique country values for the current location (excluding missing values)\n",
    "        countries = df[mask][\"country\"].dropna().unique()\n",
    "        \n",
    "        # if there is exactly one non-missing country value, overwrite all country values\n",
    "        # for that location (this will essentially just overwrite the missing state values)\n",
    "        if len(countries) == 1:\n",
    "            df.loc[mask, \"country\"] = countries[0] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aac080c",
   "metadata": {},
   "source": [
    "You may have noticed that the function above uses the reserved keyword `raise` and the built-in object `ValueError`. In Python, it is possible to \"manually\" force the Python interpreter to halt the execution of a program and display an error message. This is called raising an exception. An exception is just an error that occurs while a Python program is running. For example, the code cell bellow raises a `ValueError` - a type of exception:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e8fa014a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "custom error message",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [52]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstart\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcustom error message\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: custom error message"
     ]
    }
   ],
   "source": [
    "print(\"start\")\n",
    "raise ValueError(\"custom error message\")\n",
    "print(\"end\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d28c63b",
   "metadata": {},
   "source": [
    "As we can see, the `print(\"end\")` statement was not executed. There are many different types of errors in Python, many of which you have likely already seen: `NameError`, `TypeError`, `ValueError` etc. These can exceptions can be raised in our code whenever we want to, in order to prevent unwanted behavior.\n",
    "\n",
    "For example, the `fill_in_missing_countries()` function accepts any value as the `col_to_use` argument. However, in reality, this function was created with only two columns in mind - the \"city\" and \"state\" columns. Passing in some other column name could result in unintended consequences, however, Python by itself wouldn't necessarily raise an exception. If we come back to this code in the future, we might forget this - \"manually\" raising an exception gives us additional protection from those unintended consequences. Similarly, if someone else was to use our function, they might accidentally use our function \"incorrectly\". This is why adding statements which raise exceptions to our code can be a good idea."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d11558",
   "metadata": {},
   "source": [
    "Ok, so we have defined a function that will fill in the missing country values. Let's check again what percentage of country values are missing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f8bb4059",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1203754419160484"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = df[\"country\"].isna()\n",
    "len(df[mask]) / len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0d753a",
   "metadata": {},
   "source": [
    "Ok, so around 12% of the country values are missing. Let's call the `fill_in_missing_countries()` function and fill in some of those values based on the \"city\" column:\n",
    "\n",
    "**Note:** the code in the cell below can take up to 3 minutes to execute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "79cf8188",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fill_in_missing_countries(df, \"city\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c745a78",
   "metadata": {},
   "source": [
    "Let's check what percentage of country values are missing now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2312855b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11347906189314345"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = df[\"country\"].isna()\n",
    "len(df[mask]) / len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8393b36d",
   "metadata": {},
   "source": [
    "We've managed to decrease the percentage of missing country values by a bit. Now let's call the `fill_in_missing_countries()` function again, but this time let's pass in \"state\" as the `col_to_use` argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3da13c30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05734949957675646"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fill_in_missing_countries(df, \"state\")\n",
    "mask = df[\"country\"].isna()\n",
    "len(df[mask]) / len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df8ebf0",
   "metadata": {},
   "source": [
    "This time we've filled in more missing country values, bringing down the total percentage of missing country values to about 5.7%. Let's move on to the next step in our data preparation process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66df471d",
   "metadata": {},
   "source": [
    "# 6. Removing duplicate data <a id='removing-duplicate-data'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74b7964",
   "metadata": {},
   "source": [
    "The second question we want to answer in our analysis pertains to the duration of UFO sightings. Therefore, we will be using the \"duration\" column. However, there are two columns that contain data regarding the duration of the UFO sighting. Let's remove one of those columns, since having both of those columns means we have unnecessary, duplicate data.\n",
    "\n",
    "First let's take a look at those two columns and decide which one to remove."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f045ed01",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration (seconds)</th>\n",
       "      <th>duration (hours/min)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2700.0</td>\n",
       "      <td>45 minutes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7200.0</td>\n",
       "      <td>1-2 hrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20.0</td>\n",
       "      <td>20 seconds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20.0</td>\n",
       "      <td>1/2 hour</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>900.0</td>\n",
       "      <td>15 minutes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80327</th>\n",
       "      <td>600.0</td>\n",
       "      <td>10 minutes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80328</th>\n",
       "      <td>1200.0</td>\n",
       "      <td>20 minutes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80329</th>\n",
       "      <td>1200.0</td>\n",
       "      <td>hour</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80330</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5 seconds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80331</th>\n",
       "      <td>1020.0</td>\n",
       "      <td>17 minutes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80332 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       duration (seconds) duration (hours/min)\n",
       "0                  2700.0           45 minutes\n",
       "1                  7200.0              1-2 hrs\n",
       "2                    20.0           20 seconds\n",
       "3                    20.0             1/2 hour\n",
       "4                   900.0           15 minutes\n",
       "...                   ...                  ...\n",
       "80327               600.0           10 minutes\n",
       "80328              1200.0           20 minutes\n",
       "80329              1200.0                 hour\n",
       "80330                 5.0            5 seconds\n",
       "80331              1020.0           17 minutes\n",
       "\n",
       "[80332 rows x 2 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_names = [\"duration (seconds)\", \"duration (hours/min)\"]\n",
    "df[col_names]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9bede56",
   "metadata": {},
   "source": [
    "**Note**: there is some discrepancy between the data in the \"duration (seconds)\" column and the \"duration (hours/min)\" column. For the purpose of this course, we will ignore it; however, in a real-life situation, it would be a good idea to figure out, which column contains the more accurate data (if possible); alternatively, one could measure the discrepancy between the data in the two columns and discuss the impact it has on the analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d07b53b1",
   "metadata": {},
   "source": [
    "Data pertaining to the duration of an event is in essence numerical. Therefore, the \"duration (seconds)\" column looks like a better candidate to keep at first glance, since it seems to contain only numbers and no text. The \"duration hours/min\" column contains both numbers and text. Additionally, we can see that the \"duration hours/min\" column contains values such as \"1/2 hour\", \"hour\" and \"1-2 hrs\" - there is no clear format. This lack of structure in the data makes it more challenging to work with.\n",
    "\n",
    "Taking all of the above into consideration, it is clear that we should keep the \"duration (seconds)\" column and remove the \"duration (hours/min)\" column. We can remove the unnecessary column via the `DataFrame.drop()` method:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "97942f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(\"duration (hours/min)\", axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "931eb018",
   "metadata": {},
   "source": [
    "The column has been removed, which we can double check by looking at all the columns in dataframe (and see that the \"durations (hours/min)\" column is no longer there):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5a1864f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['datetime', 'city', 'state', 'country', 'shape', 'duration (seconds)',\n",
       "       'comments', 'date posted', 'latitude', 'longitude '],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d8c2ad",
   "metadata": {},
   "source": [
    "# 7. Saving the processed dataset to a file <a id='saving-the-processed-dataset-to-a-file'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb7d5042",
   "metadata": {},
   "source": [
    "We have now cleaned the data and it is ready to be analyzed. However, before we begin our analysis, let's save the processed version of the dataset, so that we can simply load it in the future, without having to clean the data again.\n",
    "\n",
    "We can save a `DataFrame` to a csv file via the `DataFrame.to_csv()` method, like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3c4e59ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"ufo_sightings_clean.csv\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9adeeb55",
   "metadata": {},
   "source": [
    "The first argument (in the `DataFrame.to_csv()` method) is the path to the file. In the above case, it is just the name of the file, since we will be saving it in our current directory. \n",
    "\n",
    "The `sep` argument determines what separator should be used when saving the data to a file. Even though **CSV** stands for **comma-separated values**, Pandas allows us to choose a different separator. In the above case, we pass in the string `\"\\t\"` as the separator, which corresponds to the tab character. The tab character is a special character, which is often displayed as a chunk of white space (typically used for indentation). Files which use the tab character for separating values are called **TSV** files. The TSV file format is often preferred over the CSV format, due to the fact that commas frequently occur in text containing natural language. If we save such text in a CSV file, the computer will be unable to determine, which comma separates values and which comma is simply part of some text (and therefore part of a value). The tab character occurs less frequently in text (especially short text) and it often can be cleaned out from the text, without changing the text's meaning or readability.\n",
    "\n",
    "The `index` argument determines whether or not the index should be saved to the file along with the dataset. Since we have not done anything with the index, saving it is not necessary, as it will only make the file bigger."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
